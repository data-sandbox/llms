{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT4All Basics\n",
    "\n",
    "One of the few free, locally-running LLMs cleared for commercial use.\n",
    "\n",
    "**Note:** After installing `gpt4all` with pip, models are stored in `~/.cache/gpt4all/` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt4all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file.\n",
      "gptj_model_load: loading model from '/Users/account/.cache/gpt4all/ggml-gpt4all-j-v1.3-groovy.bin' - please wait ...\n",
      "gptj_model_load: n_vocab = 50400\n",
      "gptj_model_load: n_ctx   = 2048\n",
      "gptj_model_load: n_embd  = 4096\n",
      "gptj_model_load: n_head  = 16\n",
      "gptj_model_load: n_layer = 28\n",
      "gptj_model_load: n_rot   = 64\n",
      "gptj_model_load: f16     = 2\n",
      "gptj_model_load: ggml ctx size = 5401.45 MB\n",
      "gptj_model_load: kv self size  =  896.00 MB\n",
      "gptj_model_load: ................................... done\n",
      "gptj_model_load: model size =  3609.38 MB / num tensors = 285\n"
     ]
    }
   ],
   "source": [
    "gptj = gpt4all.GPT4All(\"ggml-gpt4all-j-v1.3-groovy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction: \n",
      "            The prompt below is a question to answer, a task to complete, or a conversation \n",
      "            to respond to; decide which and write an appropriate response.\n",
      "            \n",
      "### Prompt: \n",
      "Name 3 colors\n",
      "### Response:\n",
      " Blue, Green and Orange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'ggml-gpt4all-j-v1.3-groovy',\n",
       " 'usage': {'prompt_tokens': 239, 'completion_tokens': 23, 'total_tokens': 262},\n",
       " 'choices': [{'message': {'role': 'assistant',\n",
       "    'content': ' Blue, Green and Orange'}}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Name 3 colors\"}]\n",
    "gptj.chat_completion(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the prompt from the message should make things easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction: \n",
      "            The prompt below is a question to answer, a task to complete, or a conversation \n",
      "            to respond to; decide which and write an appropriate response.\n",
      "            \n",
      "### Prompt: \n",
      "Name 3 colors\n",
      "### Response:\n",
      " Blue, Green and Red\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'ggml-gpt4all-j-v1.3-groovy',\n",
       " 'usage': {'prompt_tokens': 239, 'completion_tokens': 20, 'total_tokens': 259},\n",
       " 'choices': [{'message': {'role': 'assistant',\n",
       "    'content': ' Blue, Green and Red'}}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Name 3 colors\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "gptj.chat_completion(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction: \n",
      "            The prompt below is a question to answer, a task to complete, or a conversation \n",
      "            to respond to; decide which and write an appropriate response.\n",
      "            \n",
      "### Prompt: \n",
      "Name 3 colors\n",
      "### Response:\n",
      " Blue, Green and Red\n",
      " Blue, Green and Red\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Name 3 colors\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "response = gptj.chat_completion(messages)\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: see if API documentation exists to have `GPT4All` output just the response "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia article on LLMs\n",
    "text = \"A large language model (LLM) is a language model consisting of a neural network with many parameters (typically billions of weights or more), trained on large quantities of unlabeled text using self-supervised learning or semi-supervised learning.[1] LLMs emerged around 2018 and perform well at a wide variety of tasks. This has shifted the focus of natural language processing research away from the previous paradigm of training specialized supervised models for specific tasks.[2]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction: \n",
      "            The prompt below is a question to answer, a task to complete, or a conversation \n",
      "            to respond to; decide which and write an appropriate response.\n",
      "            \n",
      "### Prompt: \n",
      "\n",
      "Summarize the following text delimited by triple backticks \\ \n",
      "into two sentences.\n",
      "```A large language model (LLM) is a language model consisting of a neural network with many parameters (typically billions of weights or more), trained on large quantities of unlabeled text using self-supervised learning or semi-supervised learning.[1] LLMs emerged around 2018 and perform well at a wide variety of tasks. This has shifted the focus of natural language processing research away from the previous paradigm of training specialized supervised models for specific tasks.[2]```\n",
      "\n",
      "### Response:\n",
      " The prompt is asking for a summary of the text that follows. The response should be in two sentences, with the text enclosed within triple backticks.```A large language model (LLM) is a type of artificial intelligence that consists of a neural network with many parameters, trained on large quantities of unlabeled text using self-supervised learning or semi-supervised learning. It emerged in 2018 and has been shown to perform well at a wide range of tasks. This shift in focus has led to a decrease in the use of specialized supervised models for specific tasks.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'ggml-gpt4all-j-v1.3-groovy',\n",
       " 'usage': {'prompt_tokens': 800,\n",
       "  'completion_tokens': 566,\n",
       "  'total_tokens': 1366},\n",
       " 'choices': [{'message': {'role': 'assistant',\n",
       "    'content': ' The prompt is asking for a summary of the text that follows. The response should be in two sentences, with the text enclosed within triple backticks.```A large language model (LLM) is a type of artificial intelligence that consists of a neural network with many parameters, trained on large quantities of unlabeled text using self-supervised learning or semi-supervised learning. It emerged in 2018 and has been shown to perform well at a wide range of tasks. This shift in focus has led to a decrease in the use of specialized supervised models for specific tasks.'}}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Summarize the following text delimited by triple backticks \\ \n",
    "into two sentences.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "gptj.chat_completion(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I gave the same prompt to `GPT3.5` in my `GPT-3_basics.ipynb` notebook and it did a significantly better job at following directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction: \n",
      "            The prompt below is a question to answer, a task to complete, or a conversation \n",
      "            to respond to; decide which and write an appropriate response.\n",
      "            \n",
      "### Prompt: \n",
      "\n",
      "Summarize the following text delimited by triple backticks. \\ \n",
      "Use two bullet points. Be concise in your wording.\n",
      "```A large language model (LLM) is a language model consisting of a neural network with many parameters (typically billions of weights or more), trained on large quantities of unlabeled text using self-supervised learning or semi-supervised learning.[1] LLMs emerged around 2018 and perform well at a wide variety of tasks. This has shifted the focus of natural language processing research away from the previous paradigm of training specialized supervised models for specific tasks.[2]```\n",
      "\n",
      "### Response:\n",
      " * A large language model (LLM) is a type of artificial intelligence that uses neural networks to process and analyze large amounts of text. It is trained on a vast amount of unclassified text using self-supervised learning or semi-supervised learning. The LLM was first developed in 2018 and has since become a popular tool for various natural language processing tasks. The shift away from the traditional paradigm of training specialized supervised models for specific tasks has led to a new focus on LLMs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'ggml-gpt4all-j-v1.3-groovy',\n",
       " 'usage': {'prompt_tokens': 832,\n",
       "  'completion_tokens': 509,\n",
       "  'total_tokens': 1341},\n",
       " 'choices': [{'message': {'role': 'assistant',\n",
       "    'content': ' * A large language model (LLM) is a type of artificial intelligence that uses neural networks to process and analyze large amounts of text. It is trained on a vast amount of unclassified text using self-supervised learning or semi-supervised learning. The LLM was first developed in 2018 and has since become a popular tool for various natural language processing tasks. The shift away from the traditional paradigm of training specialized supervised models for specific tasks has led to a new focus on LLMs.'}}]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Summarize the following text delimited by triple backticks. \\ \n",
    "Use two bullet points. Be concise in your wording.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "gptj.chat_completion(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the prompt from \"sentences\" to \"bullets\" didn't seem to do much. There may be other prompt engineering nuances to get `GPT4ALL` to work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fictiticious product review (generated by GPT-3)\n",
    "\n",
    "review = \"\"\"\n",
    "I recently purchased an electric sit stand desk and \\\n",
    "I have to say, I'm pretty impressed. The desk is easy \\\n",
    "to adjust with just the touch of a button, and it's \\\n",
    "made a huge difference in my posture and overall \\\n",
    "comfort while working. The desk is also sturdy and \\\n",
    "well-made, so I don't have to worry about it wobbling \\\n",
    "or tipping over. Overall, I'm happy with my purchase \\\n",
    "and would recommend this desk to anyone looking for a \\\n",
    "comfortable and versatile workspace.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction: \n",
      "            The prompt below is a question to answer, a task to complete, or a conversation \n",
      "            to respond to; decide which and write an appropriate response.\n",
      "            \n",
      "### Prompt: \n",
      "\n",
      "Identify the following items from the review text: \n",
      "- Item purchased by reviewer\n",
      "- Sentiment (positive or negative)\n",
      "- 5 most important keywords discussed in the review text\n",
      "\n",
      "The review is delimited with triple backticks. Format your response as a JSON object with \"item\", \"sentiment\", \"keywords\" as the keys.\n",
      "\n",
      "If the information isn't present, use \"unknown\" as the value.\n",
      "\n",
      "Format the keywords value as a list.\n",
      "\n",
      "Review text: '''\n",
      "I recently purchased an electric sit stand desk and I have to say, I'm pretty impressed. The desk is easy to adjust with just the touch of a button, and it's made a huge difference in my posture and overall comfort while working. The desk is also sturdy and well-made, so I don't have to worry about it wobbling or tipping over. Overall, I'm happy with my purchase and would recommend this desk to anyone looking for a comfortable and versatile workspace.\n",
      "'''\n",
      "\n",
      "### Response:\n",
      " {\"item\": \"electric sit stand desk\", \"sentiment\": \"positive\", \"keywords\": [{ \"item\": \"review text\", \"sentiment\": \"positive\", \"keywords\": [\"electric sit stand desk\", \"comfortable workspace\"] },{ \"item\": \"review text\", \"sentiment\": \"positive\", \"keywords\": [\"electric sit stand desk\", \"sturdy and well-made\"] },{ \"item\": \"review text\", \"sentiment\": \"positive\", \n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Item purchased by reviewer\n",
    "- Sentiment (positive or negative)\n",
    "- 5 most important keywords discussed in the review text\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"item\", \"sentiment\", \"keywords\" as the keys.\n",
    "\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "\n",
    "Format the keywords value as a list.\n",
    "\n",
    "Review text: '''{review}'''\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "response = gptj.chat_completion(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decent result given its struggles on the earlier prompts. Not sure what happened on identifying keywords."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ve_llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
