{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-3 Basics\n",
    "\n",
    "Sandbox for exploring the GPT-3 API and best practices for prompt engineering.\n",
    "\n",
    "**Table of Contents:**\n",
    "1. Prompt organization\n",
    "2. Ask for specific output structure\n",
    "3. Inferring\n",
    "4. Summarizing\n",
    "5. Transforming\n",
    "6. Expanding\n",
    "\n",
    "Resources:\n",
    "- \"ChatGPT Prompt Engineering for Developers\" Course by DeepLearning.AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prompt Organization\n",
    "\n",
    "Let's use a helper function for writing prompts. We'll focus on OpenAI's `gpt-3.5-turbo` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting up the prompt and text for processing can help with organization and readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia article on LLMs\n",
    "text = \"A large language model (LLM) is a language model consisting of a neural network with many parameters (typically billions of weights or more), trained on large quantities of unlabeled text using self-supervised learning or semi-supervised learning.[1] LLMs emerged around 2018 and perform well at a wide variety of tasks. This has shifted the focus of natural language processing research away from the previous paradigm of training specialized supervised models for specific tasks.[2]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LLM) is a neural network with billions of weights trained on large amounts of unlabeled text using self-supervised or semi-supervised learning. LLMs have shifted the focus of natural language processing research away from specialized supervised models for specific tasks.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into two sentences.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-3 shouldn't care if backslashes or newline characters are used to break up long lines. But there is a risk of newline characters effecting performance when working with LLMs in general.\n",
    "\n",
    "Let's test newline characters with the same example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia article on LLMs\n",
    "text = f\"\"\"\n",
    "A large language model (LLM) is a language model consisting of a neural \n",
    "network with many parameters (typically billions of weights or more), \n",
    "trained on large quantities of unlabeled text using self-supervised \n",
    "learning or semi-supervised learning.[1] LLMs emerged around 2018 and \n",
    "perform well at a wide variety of tasks. This has shifted the focus of \n",
    "natural language processing research away from the previous paradigm of \n",
    "training specialized supervised models for specific tasks.[2]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language models are neural networks with billions of weights trained on unlabeled text using self-supervised or semi-supervised learning, which have shifted the focus of natural language processing research away from specialized supervised models for specific tasks.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks\n",
    "into one sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ask for Specific Output Structure\n",
    "\n",
    "LLMs are great at outputting responses in specific data structures such as JSON or HTML for more efficient follow-on processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fictiticious product review (also generated by GPT-3!)\n",
    "\n",
    "review = \"\"\"\n",
    "I recently purchased an electric sit stand desk and \\\n",
    "I have to say, I'm pretty impressed. The desk is easy \\\n",
    "to adjust with just the touch of a button, and it's \\\n",
    "made a huge difference in my posture and overall \\\n",
    "comfort while working. The desk is also sturdy and \\\n",
    "well-made, so I don't have to worry about it wobbling \\\n",
    "or tipping over. Overall, I'm happy with my purchase \\\n",
    "and would recommend this desk to anyone looking for a \\\n",
    "comfortable and versatile workspace.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"item\": \"electric sit stand desk\",\n",
      "    \"sentiment\": \"positive\",\n",
      "    \"keywords\": [\"adjust\", \"posture\", \"comfort\", \"sturdy\", \"versatile\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Item purchased by reviewer\n",
    "- Sentiment (positive or negative)\n",
    "- 5 most important keywords discussed in the text\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"item\", \"sentiment\", \"keywords\" as the keys.\n",
    "\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "\n",
    "Format the keywords value as a list.\n",
    "\n",
    "Review text: '''{review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inferring\n",
    "\n",
    "Inferring is when an LLM takes in text and performs some analysis on it, such as extracting labels, sentiments, summaries, etc.\n",
    "\n",
    "This is where the power of LLMs shines. In a traditional ML workflow, a new model must be trained and deployed for every task such as identifying labels or analyzing sentiment. In contrast, a LLM can skip the training step and be used across multiple tasks by simply engineering different prompts, drastically accelerating development.\n",
    "\n",
    "In the example under section \"2. Ask for Specific Output Structure\", GPT-3 is able to identify the item name, sentiment, and main keywords of a product review without need any additional training steps! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Summarizing\n",
    "\n",
    "Summarizing text is one of the most interesting use cases of LLMs. Imagine you're a large e-commerce website interested in analyzing product reviews. Having a human read through hundreds or thousands of reviews would be a very time-consuming task. An LLM can greatly streamline this process by summarizing each review into a smaller, more efficient summary, enabling a human to read through significantly more reviews in the same amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fictiticious product reviews for a manual coffee grinder (also generated by GPT-3!)\n",
    "review1 = \"This manual coffee grinder is a game-changer! I've been using it for a few weeks now and I can't believe how much better my coffee tastes. The grind is consistent and the process is so satisfying. Plus, it's compact and easy to store. I highly recommend this grinder to any coffee lover out there!\"\n",
    "\n",
    "review2 = \"I was really excited to try this manual coffee grinder, but unfortunately it didn't live up to my expectations. The grind wasn't as consistent as I had hoped and it took a lot of effort to grind even a small amount of coffee. I also found it difficult to clean. Overall, I wouldn't recommend this grinder.\"\n",
    "\n",
    "review3 = \"I absolutely love this manual coffee grinder! It's so easy to use and the grind is perfect every time. I also appreciate that it's made of high-quality materials and feels really sturdy. It's definitely worth the investment if you're serious about your coffee.\"\n",
    "\n",
    "review4 = \"I have mixed feelings about this manual coffee grinder. On one hand, it's really well-made and looks great on my countertop. On the other hand, it takes a lot of effort to grind even a small amount of coffee and the grind isn't as consistent as I would like. If you're willing to put in the work, it's a decent option, but there are probably better grinders out there.\"\n",
    "\n",
    "reviews = [review1, review2, review3, review4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"sentiment\": \"positive\",\n",
      "    \"summary\": \"This manual coffee grinder is a game-changer! The grind is consistent and the process is satisfying. It's compact and easy to store. Highly recommended for any coffee lover!\"\n",
      "} \n",
      "\n",
      "{\n",
      "    \"sentiment\": \"negative\",\n",
      "    \"summary\": \"Disappointing manual coffee grinder with inconsistent grind and difficult to clean. Not recommended.\"\n",
      "} \n",
      "\n",
      "{\n",
      "    \"sentiment\": \"positive\",\n",
      "    \"summary\": \"The manual coffee grinder is easy to use and made of high-quality materials. The grind is perfect every time, making it worth the investment for serious coffee lovers.\"\n",
      "} \n",
      "\n",
      "{\n",
      "    \"sentiment\": \"neutral\",\n",
      "    \"summary\": \"Mixed feelings about this manual coffee grinder. Well-made and looks great, but requires a lot of effort to grind and the grind isn't consistent. Decent option if willing to put in the work, but better grinders available.\"\n",
      "} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for review in reviews:\n",
    "    prompt = f\"\"\"\n",
    "    Your task is to generate a short summary of a product \\ \n",
    "    review from an ecommerce site.\n",
    "    \n",
    "    Also identify the sentiment as either \"positive\", \\\n",
    "    \"negative\", or \"neutral\".\n",
    "    \n",
    "    Format your response as a JSON object with \\\n",
    "    \"sentiment\" and \"summary\" as the keys.\n",
    "\n",
    "    Summarize the review below, delimited by triple \\\n",
    "    backticks in at most 40 words. \n",
    "\n",
    "    Review: ```{review}```\n",
    "    \"\"\"\n",
    "\n",
    "    response = get_completion(prompt)\n",
    "    print(response, \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-3 appears to work best when each API call is small and singular. I first attempted the above as one single API call to process all four reviews rather than using a for loop to process each review in a separate API call. In the former attempt, I would get a connection timeout error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web links\n",
    "I've had mixed results with feeding urls to the model. Sometimes it works, sometimes GPT-3 errors and says it \"cannot access the internet and browse articles\". Below is an example of that such error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, as an AI language model, I cannot access the internet and browse articles. Can you please provide the article or a sample text for me to identify the sections and summarize them?\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to identify all the sections mentioned \\\n",
    "in an article and summarize the text in them. Return \\\n",
    "your response in the following format for each identified \\\n",
    "section:\n",
    "- Section:\n",
    "- Summary:\n",
    "\n",
    "Each summary should be at least 50 words.\n",
    "\n",
    "The article is found at the url below, \\\n",
    "delimited by single quotes. \n",
    "\n",
    "'https://pravash-techie.medium.com/python-habbits-that-give-away-inexperience-99c00fbeb835'\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Transforming"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Expanding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
